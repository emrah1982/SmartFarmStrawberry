{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS (used by nbconvert / papermill)\n",
    "# You can override these via papermill or by editing here before execution\n",
    "API_KEY = globals().get('API_KEY', 'YOUR_API_KEY_HERE')  # Roboflow API Key\n",
    "SELECTED_DATASET = globals().get('SELECTED_DATASET', 1)  # 1..5 (updated for new dataset)\n",
    "VERSION = globals().get('VERSION', 1)  # Default version 1 for new dataset\n",
    "print(f\"Parameters -> SELECTED_DATASET={SELECTED_DATASET}, VERSION={VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV & CWD SETUP + DATASET GUARD (nbconvert-safe)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Prefer environment var if provided (e.g., set in Colab before nbconvert)\n",
    "API_KEY = os.environ.get('ROBOFLOW_API_KEY', API_KEY)\n",
    "\n",
    "# Ensure working directory is repository root (avoid SmartFarmStrawberry/SmartFarmStrawberry nesting)\n",
    "repo_name = 'SmartFarmStrawberry'\n",
    "cwd = Path.cwd()\n",
    "if cwd.name != repo_name and (cwd / repo_name).exists():\n",
    "    os.chdir(cwd / repo_name)\n",
    "    print(f\"Changed CWD to repo root: {Path.cwd()}\")\n",
    "\n",
    "# Dataset guard: if datasets/roboflow/data.yaml is missing, try to download via Roboflow\n",
    "DATASET_DIR = Path('datasets/roboflow')\n",
    "DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_YAML = DATASET_DIR / 'data.yaml'\n",
    "\n",
    "if not DATA_YAML.exists():\n",
    "    print(\"data.yaml not found, attempting Roboflow download...\")\n",
    "    if not API_KEY or API_KEY == 'YOUR_API_KEY_HERE':\n",
    "        raise RuntimeError(\n",
    "            \"Roboflow API_KEY is not set.\\n\"\n",
    "            \"Solution:\\n\"\n",
    "            \"1. Get API key from https://app.roboflow.com/settings/api\\n\"\n",
    "            \"2. In Colab: Add to Secrets (ğŸ”‘ icon) as ROBOFLOW_API_KEY\\n\"\n",
    "            \"3. Or set: os.environ['ROBOFLOW_API_KEY'] = 'your_key' before running nbconvert\"\n",
    "        )\n",
    "\n",
    "    from roboflow import Roboflow\n",
    "\n",
    "    # Updated dataset options - using working datasets for now\n",
    "    DATASET_OPTIONS = {\n",
    "        1: {\"workspace\": \"strawberry-detection\", \"project\": \"strawberry-detection-dataset\", \"version\": 3, \"name\": \"Strawberry Detection (Fallback)\"},\n",
    "        2: {\"workspace\": \"strawberry-detection\", \"project\": \"strawberry-detection-dataset\", \"version\": 3, \"name\": \"Strawberry Detection\"},\n",
    "        3: {\"workspace\": \"object-detection\", \"project\": \"fruit-detection-strawberry\", \"version\": 2, \"name\": \"Fruit Detection\"},\n",
    "        4: {\"workspace\": \"agriculture\", \"project\": \"strawberry-field-detection\", \"version\": 1, \"name\": \"Agricultural Strawberry\"},\n",
    "        5: {\"workspace\": \"fruit-detection-empsc\", \"project\": \"strawberry_ripe\", \"version\": 1, \"name\": \"Strawberry Ripe\"},\n",
    "    }\n",
    "\n",
    "    ds = DATASET_OPTIONS.get(int(SELECTED_DATASET), DATASET_OPTIONS[1])\n",
    "    WORKSPACE, PROJECT = ds[\"workspace\"], ds[\"project\"]\n",
    "    VERSION = ds[\"version\"]  # Use dataset-specific version\n",
    "\n",
    "    print(f\"Downloading dataset â†’ {ds['name']} ({WORKSPACE}/{PROJECT}, v{VERSION})\")\n",
    "    \n",
    "    try:\n",
    "        rf = Roboflow(api_key=API_KEY)\n",
    "        project = rf.workspace(WORKSPACE).project(PROJECT)\n",
    "        dataset = project.version(int(VERSION)).download(\"yolov8\", location=str(DATASET_DIR))\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        if \"Version number\" in str(e):\n",
    "            print(f\"\\nâš ï¸ Version {VERSION} not found for {PROJECT}\")\n",
    "            print(f\"ğŸ’¡ Check available versions at: https://universe.roboflow.com/{WORKSPACE}/{PROJECT}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error downloading dataset: {e}\")\n",
    "        print(\"ğŸ’¡ Please check your API key and workspace/project names\")\n",
    "        raise\n",
    "\n",
    "    # Some RF clients write data.yaml under a new subfolder; try to locate and move/copy it if needed\n",
    "    possible_yaml = list(DATASET_DIR.rglob('data.yaml'))\n",
    "    if possible_yaml and not DATA_YAML.exists():\n",
    "        # Prefer the deepest data.yaml (usually correct)\n",
    "        src = sorted(possible_yaml, key=lambda p: len(p.as_posix()))[-1]\n",
    "        if src != DATA_YAML:\n",
    "            import shutil\n",
    "            shutil.copy2(src, DATA_YAML)\n",
    "    \n",
    "    if DATA_YAML.exists():\n",
    "        print(\"âœ… Dataset ready at datasets/roboflow/data.yaml\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Roboflow download did not produce datasets/roboflow/data.yaml\\n\"\n",
    "            f\"Downloaded to: {DATASET_DIR}\\n\"\n",
    "            f\"Found yaml files: {possible_yaml}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“ Strawberry Vision - Production Colab Notebook\n",
    "\n",
    "Bu notebook, doÄŸrulanmÄ±ÅŸ Roboflow dataset linkleri ve proje config dosyalarÄ±nÄ± kullanarak YOLOv8 Ã§ilek tespit modeli eÄŸitir.\n",
    "\n",
    "## ğŸ“‹ Ã–zellikler\n",
    "- âœ… **4 DoÄŸrulanmÄ±ÅŸ Roboflow Dataset** - Test edilmiÅŸ linkler\n",
    "- âœ… **Google Drive Entegrasyonu** - Otomatik yedekleme\n",
    "- âœ… **Her 10 Epoch Checkpoint** - GÃ¼venli eÄŸitim\n",
    "- âœ… **Config DosyalarÄ±** - Proje standartlarÄ±na uygun\n",
    "- âœ… **Otomatik SÄ±nÄ±f Mapping** - Standart format\n",
    "\n",
    "## ğŸ¯ HÄ±zlÄ± BaÅŸlangÄ±Ã§\n",
    "1. Runtime > Change runtime type > **GPU**\n",
    "2. TÃ¼m hÃ¼creleri Ã§alÄ±ÅŸtÄ±r\n",
    "3. API key gir (BÃ¶lÃ¼m 3)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ BÃ¶lÃ¼m 1: Google Drive BaÄŸlantÄ±sÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1. Google Drive Mount\n",
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ“ Google Drive baÄŸlanÄ±yor...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Proje klasÃ¶r yapÄ±sÄ±\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/StrawberryVision'\n",
    "CHECKPOINT_DIR = f\"{DRIVE_ROOT}/checkpoints\"\n",
    "RESULTS_DIR = f\"{DRIVE_ROOT}/results\"\n",
    "MODELS_DIR = f\"{DRIVE_ROOT}/best_models\"\n",
    "\n",
    "for folder in [DRIVE_ROOT, CHECKPOINT_DIR, RESULTS_DIR, MODELS_DIR]:\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Drive baÄŸlandÄ±: {DRIVE_ROOT}\")\n",
    "print(f\"ğŸ“¦ Checkpoint: {CHECKPOINT_DIR}\")\n",
    "print(f\"ğŸ“Š Results: {RESULTS_DIR}\")\n",
    "print(f\"ğŸ† Models: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ BÃ¶lÃ¼m 2: Kurulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1. BaÄŸÄ±mlÄ±lÄ±klar\n",
    "print(\"ğŸ“¦ BaÄŸÄ±mlÄ±lÄ±klar yÃ¼kleniyor...\")\n",
    "\n",
    "!pip install -q ultralytics>=8.0.0\n",
    "!pip install -q opencv-python>=4.8.0\n",
    "!pip install -q numpy>=1.24.0\n",
    "!pip install -q matplotlib>=3.7.0\n",
    "!pip install -q roboflow>=1.1.0\n",
    "!pip install -q pyyaml>=6.0\n",
    "\n",
    "print(\"âœ… Kurulum tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2. Proje KlasÃ¶rleri\n",
    "folders = ['datasets', 'runs', 'configs']\n",
    "for folder in folders:\n",
    "    Path(folder).mkdir(exist_ok=True)\n",
    "    print(f\"âœ… {folder}/\")\n",
    "\n",
    "print(\"\\nğŸ“ Proje yapÄ±sÄ± hazÄ±r!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ DoÄŸrulanmÄ±ÅŸ Dataset Linkleri:\n",
    "\n",
    "#### 1. Yeni Strawberry Dataset ğŸ†• **Ã–NERÄ°LEN**\n",
    "- **Download Link**: https://universe.roboflow.com/ds/8stDwYxKHL?key=gAR2BTHYtu\n",
    "- **SÄ±nÄ±flar**: Dataset'e Ã¶zgÃ¼ sÄ±nÄ±flar (indirildikten sonra kontrol edilecek)\n",
    "- **Ã–zellik**: Yeni ve gÃ¼ncel dataset\n",
    "\n",
    "#### 2. Strawberry Detection Dataset\n",
    "- **Workspace**: `strawberry-detection`\n",
    "- **Project**: `strawberry-detection-dataset`\n",
    "- **Version**: 3\n",
    "- **SÄ±nÄ±flar**: strawberry\n",
    "- **Link**: https://universe.roboflow.com/strawberry-detection/strawberry-detection-dataset\n",
    "\n",
    "#### 3. Fruit Detection - Strawberry\n",
    "- **Workspace**: `object-detection`\n",
    "- **Project**: `fruit-detection-strawberry`\n",
    "- **Version**: 2\n",
    "- **SÄ±nÄ±flar**: strawberry (Ã§eÅŸitli olgunluk)\n",
    "- **Link**: https://universe.roboflow.com/object-detection/fruit-detection-strawberry\n",
    "\n",
    "#### 4. Agricultural Strawberry Dataset\n",
    "- **Workspace**: `agriculture`\n",
    "- **Project**: `strawberry-field-detection`\n",
    "- **Version**: 1\n",
    "- **SÄ±nÄ±flar**: strawberry_ripe, strawberry_unripe\n",
    "- **Link**: https://universe.roboflow.com/agriculture/strawberry-field-detection\n",
    "\n",
    "#### 5. Strawberry Ripe Detection\n",
    "- **Workspace**: `fruit-detection-empsc`\n",
    "- **Project**: `strawberry_ripe`\n",
    "- **Version**: 1\n",
    "- **SÄ±nÄ±flar**: ripe strawberry\n",
    "- **Link**: https://universe.roboflow.com/fruit-detection-empsc/strawberry_ripe\n",
    "\n",
    "### ğŸ”‘ API Key Alma:\n",
    "https://app.roboflow.com/settings/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1. Dataset SeÃ§imi ve API AyarlarÄ±\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# âš ï¸ API KEY'Ä°NÄ°ZÄ° BURAYA GÄ°RÄ°N\n",
    "API_KEY = \"YOUR_API_KEY_HERE\"\n",
    "\n",
    "# Dataset seÃ§imi (aÅŸaÄŸÄ±dakilerden birini seÃ§in)\n",
    "DATASET_OPTIONS = {\n",
    "    1: {\"workspace\": \"strawberry-detection\", \"project\": \"strawberry-detection-dataset\", \"version\": 3, \"name\": \"Strawberry Detection (Test EdilmiÅŸ)\"},\n",
    "    2: {\"workspace\": \"strawberry-detection\", \"project\": \"strawberry-detection-dataset\", \"version\": 3, \"name\": \"Strawberry Detection\"},\n",
    "    3: {\"workspace\": \"object-detection\", \"project\": \"fruit-detection-strawberry\", \"version\": 2, \"name\": \"Fruit Detection\"},\n",
    "    4: {\"workspace\": \"agriculture\", \"project\": \"strawberry-field-detection\", \"version\": 1, \"name\": \"Agricultural Strawberry\"},\n",
    "    5: {\"workspace\": \"fruit-detection-empsc\", \"project\": \"strawberry_ripe\", \"version\": 1, \"name\": \"Strawberry Ripe\"},\n",
    "}\n",
    "\n",
    "# Hangi dataset'i kullanacaksÄ±nÄ±z? (1-5)\n",
    "SELECTED_DATASET = 1  # â­ Ã–nerilen: 1 (Strawberry Detection - Test EdilmiÅŸ)\n",
    "\n",
    "dataset_info = DATASET_OPTIONS[SELECTED_DATASET]\n",
    "WORKSPACE = dataset_info[\"workspace\"]\n",
    "PROJECT = dataset_info[\"project\"]\n",
    "VERSION = dataset_info[\"version\"]\n",
    "\n",
    "print(f\"ğŸ“¥ SeÃ§ilen Dataset: {dataset_info['name']}\")\n",
    "print(f\"ğŸ“¦ Workspace/Project: {WORKSPACE}/{PROJECT}\")\n",
    "print(f\"ğŸ”¢ Version: {VERSION}\")\n",
    "print(f\"ğŸ’¡ Dataset link: https://universe.roboflow.com/{WORKSPACE}/{PROJECT}\")\n",
    "\n",
    "# Not: Yeni dataset (8stDwYxKHL) iÃ§in Roboflow API entegrasyonu gÃ¼ncellenmektedir\n",
    "# Åu an iÃ§in test edilmiÅŸ Strawberry Detection dataset kullanÄ±lmasÄ± Ã¶nerilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2. Dataset Ä°ndirme ve Test\n",
    "if API_KEY == \"YOUR_API_KEY_HERE\":\n",
    "    print(\"âš ï¸  LÃ¼tfen API KEY'inizi girin!\")\n",
    "    print(\"\\nğŸ”‘ API Key almak iÃ§in:\")\n",
    "    print(\"   1. https://app.roboflow.com adresine gidin\")\n",
    "    print(\"   2. GiriÅŸ yapÄ±n\")\n",
    "    print(\"   3. Settings > API > Copy API Key\")\n",
    "else:\n",
    "    print(\"ğŸ”„ Roboflow'dan indiriliyor...\")\n",
    "    print(f\"ğŸ“¦ Dataset: {WORKSPACE}/{PROJECT} v{VERSION}\\n\")\n",
    "    \n",
    "    try:\n",
    "        rf = Roboflow(api_key=API_KEY)\n",
    "        project = rf.workspace(WORKSPACE).project(PROJECT)\n",
    "        dataset = project.version(VERSION).download(\"yolov8\", location=\"datasets/roboflow\")\n",
    "        \n",
    "        print(\"\\nâœ… Dataset baÅŸarÄ±yla indirildi!\")\n",
    "        print(f\"ğŸ“ Konum: datasets/roboflow\")\n",
    "        print(f\"ğŸ“Š Dataset bilgileri: {dataset.location}\")\n",
    "        \n",
    "        # Dataset iÃ§eriÄŸini kontrol et\n",
    "        data_yaml_path = \"datasets/roboflow/data.yaml\"\n",
    "        if os.path.exists(data_yaml_path):\n",
    "            import yaml\n",
    "            with open(data_yaml_path, 'r') as f:\n",
    "                data_config = yaml.safe_load(f)\n",
    "            print(f\"\\nğŸ“‹ SÄ±nÄ±flar: {data_config.get('names', [])}\")\n",
    "            print(f\"ğŸ“Š SÄ±nÄ±f sayÄ±sÄ±: {data_config.get('nc', 0)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Hata: {e}\")\n",
    "        print(\"\\nğŸ’¡ Sorun Giderme:\")\n",
    "        print(\"   1. API key'inizi kontrol edin\")\n",
    "        print(\"   2. Workspace/Project adlarÄ±nÄ± kontrol edin\")\n",
    "        print(\"   3. Dataset'e eriÅŸim izniniz olduÄŸundan emin olun\")\n",
    "        print(\"   4. Version numarasÄ±nÄ± kontrol edin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ BÃ¶lÃ¼m 4: SÄ±nÄ±f Etiketlerini Standardize Et\n",
    "\n",
    "### Standart SÄ±nÄ±flar (configs/strawberry_data.yaml):\n",
    "- **0: strawberry_ripe** - Olgun Ã§ilek (kÄ±rmÄ±zÄ± renk baskÄ±n)\n",
    "- **1: strawberry_semi_ripe** - YarÄ± olgun Ã§ilek (kÄ±rmÄ±zÄ±-beyaz)\n",
    "- **2: strawberry_unripe** - Olgun olmayan Ã§ilek (yeÅŸil-beyaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. SÄ±nÄ±f Mapping (3-RoboflowDatasetKullanimi.md'den)\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "CLASS_MAPPING = {\n",
    "    \"ripe\": \"strawberry_ripe\",\n",
    "    \"semi-ripe\": \"strawberry_semi_ripe\",\n",
    "    \"semi_ripe\": \"strawberry_semi_ripe\",\n",
    "    \"unripe\": \"strawberry_unripe\",\n",
    "    \"green\": \"strawberry_unripe\",\n",
    "    \"strawberry\": \"strawberry_ripe\",\n",
    "}\n",
    "\n",
    "STANDARD_CLASSES = {\n",
    "    0: \"strawberry_ripe\",\n",
    "    1: \"strawberry_semi_ripe\",\n",
    "    2: \"strawberry_unripe\",\n",
    "}\n",
    "\n",
    "print(\"âœ… SÄ±nÄ±f mapping hazÄ±r\")\n",
    "print(f\"ğŸ“‹ Mapping kurallarÄ±: {len(CLASS_MAPPING)} kural\")\n",
    "print(f\"ğŸ¯ Standart sÄ±nÄ±flar: {STANDARD_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Label DosyalarÄ±nÄ± GÃ¼ncelle\n",
    "yaml_path = \"datasets/roboflow/data.yaml\"\n",
    "\n",
    "if os.path.exists(yaml_path):\n",
    "    # Eski sÄ±nÄ±flarÄ± oku\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    old_names = data_config.get('names', [])\n",
    "    print(f\"ğŸ“‹ Eski sÄ±nÄ±flar: {old_names}\")\n",
    "    \n",
    "    # ID mapping oluÅŸtur\n",
    "    if isinstance(old_names, list):\n",
    "        old_names = {i: name for i, name in enumerate(old_names)}\n",
    "    \n",
    "    id_mapping = {}\n",
    "    for old_id, old_name in old_names.items():\n",
    "        mapped_name = CLASS_MAPPING.get(old_name.lower(), \"strawberry_ripe\")\n",
    "        for new_id, new_name in STANDARD_CLASSES.items():\n",
    "            if mapped_name == new_name:\n",
    "                id_mapping[old_id] = new_id\n",
    "                break\n",
    "    \n",
    "    print(f\"ğŸ”„ ID Mapping: {id_mapping}\")\n",
    "    \n",
    "    # Label dosyalarÄ±nÄ± gÃ¼ncelle\n",
    "    def update_labels(labels_dir, id_mapping):\n",
    "        updated_count = 0\n",
    "        total_files = 0\n",
    "        for label_file in Path(labels_dir).glob('*.txt'):\n",
    "            total_files += 1\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    old_class_id = int(parts[0])\n",
    "                    new_class_id = id_mapping.get(old_class_id, old_class_id)\n",
    "                    parts[0] = str(new_class_id)\n",
    "                    new_lines.append(' '.join(parts) + '\\n')\n",
    "                    if new_class_id != old_class_id:\n",
    "                        updated_count += 1\n",
    "            with open(label_file, 'w') as f:\n",
    "                f.writelines(new_lines)\n",
    "        return updated_count, total_files\n",
    "    \n",
    "    # Her split iÃ§in gÃ¼ncelle\n",
    "    total_updated = 0\n",
    "    total_files = 0\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        labels_dir = f\"datasets/roboflow/{split}/labels\"\n",
    "        if os.path.exists(labels_dir):\n",
    "            count, files = update_labels(labels_dir, id_mapping)\n",
    "            total_updated += count\n",
    "            total_files += files\n",
    "            print(f\"âœ… {split}: {files} dosya, {count} etiket gÃ¼ncellendi\")\n",
    "    \n",
    "    # Yeni data.yaml oluÅŸtur\n",
    "    new_data_yaml = {\n",
    "        'path': os.path.abspath('datasets/roboflow'),\n",
    "        'train': 'train/images',\n",
    "        'val': 'valid/images',\n",
    "        'test': 'test/images',\n",
    "        'nc': 3,\n",
    "        'names': STANDARD_CLASSES\n",
    "    }\n",
    "    \n",
    "    with open('datasets/roboflow/data.yaml', 'w') as f:\n",
    "        yaml.dump(new_data_yaml, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Ã–zet:\")\n",
    "    print(f\"  Toplam dosya: {total_files}\")\n",
    "    print(f\"  GÃ¼ncellenen etiket: {total_updated}\")\n",
    "    print(f\"  Standart sÄ±nÄ±flar: {STANDARD_CLASSES}\")\n",
    "    print(\"\\nâœ… data.yaml gÃ¼ncellendi\")\n",
    "else:\n",
    "    print(\"âš ï¸  data.yaml bulunamadÄ±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ BÃ¶lÃ¼m 5: Model EÄŸitimi (Config DosyalarÄ± ile)\n",
    "\n",
    "### ğŸ“‹ EÄŸitim Parametreleri (configs/train_config.yaml):\n",
    "- **Model**: yolov8n.pt\n",
    "- **Epochs**: 100\n",
    "- **Batch**: 16\n",
    "- **Save Period**: 10 (Her 10 epoch'ta kaydet)\n",
    "- **Optimizer**: AdamW\n",
    "- **Learning Rate**: 0.01\n",
    "\n",
    "### ğŸ¨ Augmentation (configs/augmentation_config.yaml):\n",
    "- HSV: h=0.015, s=0.7, v=0.4\n",
    "- Rotation: Â±10Â°\n",
    "- Flip: 0.5 (horizontal)\n",
    "- Mosaic: 1.0, Mixup: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1. EÄŸitim Config (train_config.yaml'dan)\n",
    "TRAIN_CONFIG = {\n",
    "    # Model\n",
    "    'model': 'yolov8n.pt',\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 100,\n",
    "    'batch': 16,\n",
    "    'imgsz': 640,\n",
    "    'device': 0,\n",
    "    'workers': 8,\n",
    "    \n",
    "    # Optimizer\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr0': 0.01,\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    \n",
    "    # Loss\n",
    "    'box': 7.5,\n",
    "    'cls': 0.5,\n",
    "    'dfl': 1.5,\n",
    "    \n",
    "    # Augmentation (augmentation_config.yaml'dan)\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.7,\n",
    "    'hsv_v': 0.4,\n",
    "    'degrees': 10.0,\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'shear': 0.0,\n",
    "    'perspective': 0.0,\n",
    "    'flipud': 0.0,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.1,\n",
    "    'copy_paste': 0.0,\n",
    "    \n",
    "    # Validation\n",
    "    'val': True,\n",
    "    'save': True,\n",
    "    'save_period': 10,  # â­ Her 10 epoch'ta kaydet\n",
    "    'plots': True,\n",
    "    'conf': 0.25,\n",
    "    'iou': 0.7,\n",
    "    \n",
    "    # Advanced\n",
    "    'patience': 50,\n",
    "    'resume': False,\n",
    "    'amp': True,\n",
    "    'fraction': 1.0,\n",
    "    \n",
    "    # Project\n",
    "    'project': 'runs/train',\n",
    "    'name': 'strawberry_exp',\n",
    "    'exist_ok': False,\n",
    "    'pretrained': True,\n",
    "    'verbose': True,\n",
    "    'seed': 0,\n",
    "    'deterministic': True,\n",
    "}\n",
    "\n",
    "print(\"ğŸ¯ EÄŸitim KonfigÃ¼rasyonu (train_config.yaml):\")\n",
    "print(f\"  Model: {TRAIN_CONFIG['model']}\")\n",
    "print(f\"  Epochs: {TRAIN_CONFIG['epochs']}\")\n",
    "print(f\"  Batch: {TRAIN_CONFIG['batch']}\")\n",
    "print(f\"  Save Period: {TRAIN_CONFIG['save_period']} â­\")\n",
    "print(f\"  Optimizer: {TRAIN_CONFIG['optimizer']}\")\n",
    "print(f\"  Learning Rate: {TRAIN_CONFIG['lr0']}\")\n",
    "print(f\"\\nğŸ¨ Augmentation (augmentation_config.yaml):\")\n",
    "print(f\"  HSV: h={TRAIN_CONFIG['hsv_h']}, s={TRAIN_CONFIG['hsv_s']}, v={TRAIN_CONFIG['hsv_v']}\")\n",
    "print(f\"  Rotation: Â±{TRAIN_CONFIG['degrees']}Â°\")\n",
    "print(f\"  Flip LR: {TRAIN_CONFIG['fliplr']}\")\n",
    "print(f\"  Mosaic: {TRAIN_CONFIG['mosaic']}, Mixup: {TRAIN_CONFIG['mixup']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2. Model EÄŸitimi (Dataset Guard ile)\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Dataset yolu kontrolÃ¼\n",
    "DATA_YAML_PATH = 'datasets/roboflow/data.yaml'\n",
    "if not Path(DATA_YAML_PATH).exists():\n",
    "    print(f\"âš ï¸  {DATA_YAML_PATH} bulunamadÄ±!\")\n",
    "    print(\"\\nğŸ’¡ Ã‡Ã¶zÃ¼m seÃ§enekleri:\")\n",
    "    print(\"1. Roboflow API key'inizi ayarlayÄ±n (hÃ¼cre 0 ve 1)\")\n",
    "    print(\"2. Manuel olarak dataset indirin (hÃ¼cre 9-10)\")\n",
    "    print(\"3. Alternatif: configs/strawberry_data.yaml kullanÄ±n (kendi datasetiniz varsa)\")\n",
    "    \n",
    "    # Fallback: configs/strawberry_data.yaml varsa kullan\n",
    "    FALLBACK_YAML = 'configs/strawberry_data.yaml'\n",
    "    if Path(FALLBACK_YAML).exists():\n",
    "        print(f\"\\nğŸ”„ Fallback: {FALLBACK_YAML} kullanÄ±lÄ±yor\")\n",
    "        DATA_YAML_PATH = FALLBACK_YAML\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset bulunamadÄ±. LÃ¼tfen:\\n\"\n",
    "            f\"1. ROBOFLOW_API_KEY env var'Ä±nÄ± ayarlayÄ±n\\n\"\n",
    "            f\"2. HÃ¼cre 0'da API_KEY = 'your_key' yapÄ±n\\n\"\n",
    "            f\"3. HÃ¼cre 9-10'u Ã§alÄ±ÅŸtÄ±rarak dataset indirin\"\n",
    "        )\n",
    "\n",
    "print(\"ğŸš€ Model eÄŸitimi baÅŸlÄ±yor...\")\n",
    "print(f\"ğŸ“ Dataset: {DATA_YAML_PATH}\")\n",
    "print(f\"â±ï¸  Tahmini sÃ¼re: {TRAIN_CONFIG['epochs']} epoch iÃ§in ~{TRAIN_CONFIG['epochs']//2}-{TRAIN_CONFIG['epochs']} dakika (GPU ile)\")\n",
    "print(f\"ğŸ’¾ Her {TRAIN_CONFIG['save_period']} epoch'ta checkpoint Drive'a kaydedilecek\\n\")\n",
    "\n",
    "model = YOLO(TRAIN_CONFIG['model'])\n",
    "\n",
    "start_time = time.time()\n",
    "results = model.train(\n",
    "    data=DATA_YAML_PATH,\n",
    "    **TRAIN_CONFIG\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâœ… EÄŸitim tamamlandÄ±!\")\n",
    "print(f\"â±ï¸  SÃ¼re: {training_time/60:.1f} dakika ({training_time/3600:.2f} saat)\")\n",
    "print(f\"ğŸ“Š SonuÃ§lar: {TRAIN_CONFIG['project']}/{TRAIN_CONFIG['name']}\")\n",
    "print(f\"ğŸ† En iyi model: {TRAIN_CONFIG['project']}/{TRAIN_CONFIG['name']}/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3. Checkpoint'leri Drive'a Kopyala\n",
    "results_dir = f\"{TRAIN_CONFIG['project']}/{TRAIN_CONFIG['name']}\"\n",
    "weights_dir = f\"{results_dir}/weights\"\n",
    "\n",
    "if os.path.exists(weights_dir):\n",
    "    print(\"ğŸ’¾ Checkpoint'ler Drive'a kopyalanÄ±yor...\\n\")\n",
    "    \n",
    "    drive_weights_dir = f\"{CHECKPOINT_DIR}/{TRAIN_CONFIG['name']}_weights\"\n",
    "    if os.path.exists(drive_weights_dir):\n",
    "        shutil.rmtree(drive_weights_dir)\n",
    "    shutil.copytree(weights_dir, drive_weights_dir)\n",
    "    \n",
    "    checkpoint_files = sorted(Path(drive_weights_dir).glob('*.pt'))\n",
    "    print(f\"âœ… {len(checkpoint_files)} checkpoint Drive'a kaydedildi:\")\n",
    "    for ckpt in checkpoint_files:\n",
    "        size_mb = ckpt.stat().st_size / (1024*1024)\n",
    "        print(f\"  ğŸ“¦ {ckpt.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ Drive konumu: {drive_weights_dir}\")\n",
    "else:\n",
    "    print(\"âš ï¸  Weights klasÃ¶rÃ¼ bulunamadÄ±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4. EÄŸitim Grafikleri\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"ğŸ“Š EÄŸitim SonuÃ§larÄ±:\\n\")\n",
    "\n",
    "if os.path.exists(f\"{results_dir}/results.png\"):\n",
    "    display(Image(filename=f\"{results_dir}/results.png\"))\n",
    "\n",
    "if os.path.exists(f\"{results_dir}/confusion_matrix.png\"):\n",
    "    display(Image(filename=f\"{results_dir}/confusion_matrix.png\"))\n",
    "\n",
    "if os.path.exists(f\"{results_dir}/val_batch0_pred.jpg\"):\n",
    "    display(Image(filename=f\"{results_dir}/val_batch0_pred.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” BÃ¶lÃ¼m 6: Model DeÄŸerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1. Validation Metrikleri\n",
    "best_model_path = f\"{results_dir}/weights/best.pt\"\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(\"ğŸ“Š Model deÄŸerlendiriliyor...\\n\")\n",
    "    \n",
    "    model = YOLO(best_model_path)\n",
    "    metrics = model.val(data='datasets/roboflow/data.yaml')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ“ˆ DEÄERLENDIRME SONUÃ‡LARI\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"  mAP@0.5: {metrics.box.map50:.4f}\")\n",
    "    print(f\"  mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "    print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
    "    print(f\"  Recall: {metrics.box.mr:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Hedef karÅŸÄ±laÅŸtÄ±rma\n",
    "    print(\"\\nğŸ¯ Hedef KarÅŸÄ±laÅŸtÄ±rma:\")\n",
    "    print(f\"  mAP@0.5: {metrics.box.map50:.4f} {'âœ…' if metrics.box.map50 >= 0.80 else 'âš ï¸'} (Hedef: â‰¥0.80)\")\n",
    "    print(f\"  Precision: {metrics.box.mp:.4f} {'âœ…' if metrics.box.mp >= 0.85 else 'âš ï¸'} (Hedef: â‰¥0.85)\")\n",
    "    print(f\"  Recall: {metrics.box.mr:.4f} {'âœ…' if metrics.box.mr >= 0.75 else 'âš ï¸'} (Hedef: â‰¥0.75)\")\n",
    "else:\n",
    "    print(\"âš ï¸  Model bulunamadÄ±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2. Test GÃ¶rÃ¼ntÃ¼leri ile Inference\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_images_dir = \"datasets/roboflow/valid/images\"\n",
    "test_images = list(Path(test_images_dir).glob('*.jpg'))[:5]\n",
    "\n",
    "if test_images and os.path.exists(best_model_path):\n",
    "    model = YOLO(best_model_path)\n",
    "    \n",
    "    for img_path in test_images:\n",
    "        results = model(str(img_path))\n",
    "        annotated = results[0].plot()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Tespit: {img_path.name}\")\n",
    "        plt.show()\n",
    "        \n",
    "        boxes = results[0].boxes\n",
    "        print(f\"\\n{img_path.name}: {len(boxes)} Ã§ilek tespit edildi\")\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            class_counts = {}\n",
    "            for box in boxes:\n",
    "                cls_id = int(box.cls[0])\n",
    "                cls_name = STANDARD_CLASSES[cls_id]\n",
    "                class_counts[cls_name] = class_counts.get(cls_name, 0) + 1\n",
    "            print(f\"DaÄŸÄ±lÄ±m: {class_counts}\")\n",
    "        print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"âš ï¸  Test gÃ¶rÃ¼ntÃ¼leri veya model bulunamadÄ±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ BÃ¶lÃ¼m 7: SonuÃ§larÄ± Drive'a Kaydet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1. TÃ¼m SonuÃ§larÄ± Kaydet\n",
    "if os.path.exists(results_dir):\n",
    "    print(\"ğŸ“¦ TÃ¼m sonuÃ§lar Drive'a kopyalanÄ±yor...\\n\")\n",
    "    \n",
    "    drive_results_dir = f\"{RESULTS_DIR}/{TRAIN_CONFIG['name']}\"\n",
    "    if os.path.exists(drive_results_dir):\n",
    "        shutil.rmtree(drive_results_dir)\n",
    "    shutil.copytree(results_dir, drive_results_dir)\n",
    "    \n",
    "    total_size = sum(f.stat().st_size for f in Path(drive_results_dir).rglob('*') if f.is_file())\n",
    "    \n",
    "    print(f\"âœ… SonuÃ§lar Drive'a kaydedildi\")\n",
    "    print(f\"ğŸ“ Konum: {drive_results_dir}\")\n",
    "    print(f\"ğŸ“Š Toplam boyut: {total_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    # En iyi modeli ayrÄ±ca kaydet\n",
    "    if os.path.exists(best_model_path):\n",
    "        best_model_drive = f\"{MODELS_DIR}/strawberry_best_{TRAIN_CONFIG['name']}.pt\"\n",
    "        shutil.copy(best_model_path, best_model_drive)\n",
    "        size_mb = Path(best_model_drive).stat().st_size / (1024*1024)\n",
    "        print(f\"\\nğŸ† En iyi model: {best_model_drive} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"âš ï¸  SonuÃ§ klasÃ¶rÃ¼ bulunamadÄ±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Ã–zet ve Notlar\n",
    "\n",
    "### âœ… Tamamlanan AdÄ±mlar\n",
    "1. âœ… Google Drive baÄŸlandÄ±\n",
    "2. âœ… DoÄŸrulanmÄ±ÅŸ Roboflow dataset indirildi\n",
    "3. âœ… SÄ±nÄ±f etiketleri standardize edildi (CLASS_MAPPING)\n",
    "4. âœ… Config dosyalarÄ±na gÃ¶re eÄŸitim yapÄ±ldÄ±\n",
    "5. âœ… Her 10 epoch'ta checkpoint kaydedildi\n",
    "6. âœ… Model deÄŸerlendirildi\n",
    "7. âœ… SonuÃ§lar Drive'a kaydedildi\n",
    "\n",
    "### ğŸ“¦ KullanÄ±lan Config DosyalarÄ±\n",
    "- **strawberry_data.yaml** - Dataset yapÄ±sÄ± ve sÄ±nÄ±f tanÄ±mlarÄ±\n",
    "- **train_config.yaml** - EÄŸitim parametreleri (100 epoch, batch 16, save_period 10)\n",
    "- **augmentation_config.yaml** - Augmentation stratejisi\n",
    "\n",
    "### ğŸŒ DoÄŸrulanmÄ±ÅŸ Roboflow Datasetleri\n",
    "1. â­ **fruit-detection/strawberry-ripeness** - Olgunluk sÄ±nÄ±flandÄ±rmasÄ±\n",
    "2. **strawberry-detection/strawberry-detection-dataset** - Temel tespit\n",
    "3. **object-detection/fruit-detection-strawberry** - GeniÅŸ veri\n",
    "4. **agriculture/strawberry-field-detection** - Tarla koÅŸullarÄ±\n",
    "\n",
    "### ğŸ’¾ Drive KlasÃ¶r YapÄ±sÄ±\n",
    "```\n",
    "MyDrive/StrawberryVision/\n",
    "â”œâ”€â”€ checkpoints/\n",
    "â”‚   â””â”€â”€ strawberry_exp_weights/\n",
    "â”‚       â”œâ”€â”€ epoch10.pt, epoch20.pt, ..., epoch100.pt\n",
    "â”‚       â”œâ”€â”€ best.pt\n",
    "â”‚       â””â”€â”€ last.pt\n",
    "â”œâ”€â”€ results/\n",
    "â”‚   â””â”€â”€ strawberry_exp/\n",
    "â””â”€â”€ best_models/\n",
    "    â””â”€â”€ strawberry_best_strawberry_exp.pt\n",
    "```\n",
    "\n",
    "### ğŸ“Š Performans Hedefleri\n",
    "- mAP@0.5 â‰¥ 0.80\n",
    "- Precision â‰¥ 0.85\n",
    "- Recall â‰¥ 0.75\n",
    "\n",
    "### ğŸ”§ Sorun Giderme\n",
    "- **Out of Memory**: `batch: 8` yapÄ±n\n",
    "- **YavaÅŸ EÄŸitim**: GPU kontrolÃ¼ yapÄ±n\n",
    "- **API HatasÄ±**: Workspace/Project adlarÄ±nÄ± kontrol edin\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ Tebrikler!** Modeliniz eÄŸitildi ve Google Drive'a kaydedildi."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
